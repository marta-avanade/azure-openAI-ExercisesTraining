# ğŸ“ Estructura del Proyecto

```
03_FineTunning/
â”œâ”€â”€ ğŸ“„ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias Python
â”œâ”€â”€ ğŸ“„ run_all_steps.py             # Script para ejecutar todo el proceso
â”œâ”€â”€ ğŸ“„ .env                         # Variables de entorno (configuraciÃ³n Azure)
â”‚
â”œâ”€â”€ ğŸ“‚ config/
â”‚   â””â”€â”€ ğŸ“„ config.py                # ConfiguraciÃ³n del proyecto
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                     # Datos originales (JSON de ejemplos)
â”‚   â”œâ”€â”€ ğŸ“‚ processed/               # Datos procesados (prompts JSONL)
â”‚   â”œâ”€â”€ ğŸ“‚ training/                # Datos de entrenamiento
â”‚   â””â”€â”€ ğŸ“‚ validation/              # Datos de validaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ ğŸ“„ 01_create_examples.py    # Crear ejemplos de intenciones
â”‚   â”œâ”€â”€ ğŸ“„ 02_create_prompts.py     # Generar prompts para entrenamiento
â”‚   â”œâ”€â”€ ğŸ“„ 03_split_data.py         # Dividir datos train/validation
â”‚   â”œâ”€â”€ ğŸ“„ 04_prepare_data.py       # Preparar datos para fine-tuning
â”‚   â”œâ”€â”€ ğŸ“„ 05_fine_tuning.py        # Ejecutar fine-tuning en Azure
â”‚   â”œâ”€â”€ ğŸ“„ 06_deploy_model.py       # Desplegar modelo
â”‚   â”œâ”€â”€ ğŸ“„ 07_test_model.py         # Probar modelo con casos de prueba
â”‚   â””â”€â”€ ğŸ“„ 08_analyze_results.py    # Analizar resultados y mejoras
â”‚
â”œâ”€â”€ ğŸ“‚ models/                      # InformaciÃ³n de modelos (futuro)
â”œâ”€â”€ ğŸ“‚ results/                     # Resultados, reportes y mÃ©tricas
â”œâ”€â”€ ğŸ“‚ tests/                       # Casos de prueba adicionales
â””â”€â”€ ğŸ“‚ logs/                        # Logs del proceso
```

## ï¿½ DescripciÃ³n Detallada de Scripts

### ğŸ”¸ **01_create_examples.py** - Crear Ejemplos de Intenciones
**PropÃ³sito**: Genera el dataset inicial con ejemplos de texto para cada intenciÃ³n de la tienda.

**QuÃ© hace**:
- Crea 48 ejemplos (12 por cada intenciÃ³n): `comprar`, `devolver`, `queja`, `consulta`
- Cada ejemplo es una frase realista que un cliente dirÃ­a en una tienda de ropa
- Guarda los datos en formato JSON en `data/raw/intent_examples.json`
- Valida que todas las intenciones tengan suficientes ejemplos (mÃ­n. 10 para Azure OpenAI)

**Entrada**: Ninguna (genera datos desde cero)
**Salida**: `data/raw/intent_examples.json` con estructura:
```json
{
  "comprar": ["Me gustarÃ­a comprar esta camiseta", "..."],
  "devolver": ["Quiero devolver este producto", "..."],
  ...
}
```

### ğŸ”¸ **02_create_prompts.py** - Generar Prompts para Entrenamiento
**PropÃ³sito**: Convierte los ejemplos JSON en prompts estructurados para fine-tuning.

**QuÃ© hace**:
- Lee el archivo `intent_examples.json` del paso anterior
- Crea un prompt del sistema que explica la tarea de clasificaciÃ³n
- Para cada ejemplo, genera un prompt con 3 mensajes:
  - `system`: Instrucciones de clasificaciÃ³n
  - `user`: El texto del cliente
  - `assistant`: La intenciÃ³n correcta
- Valida que todos los prompts tengan el formato correcto
- Guarda en formato JSONL (lÃ­nea por prompt) en `data/processed/training_prompts.jsonl`

**Entrada**: `data/raw/intent_examples.json`
**Salida**: `data/processed/training_prompts.jsonl` (48 prompts)

### ğŸ”¸ **03_split_data.py** - Dividir Datos en Entrenamiento/ValidaciÃ³n
**PropÃ³sito**: Separa los datos en conjuntos de entrenamiento y validaciÃ³n de forma balanceada.

**QuÃ© hace**:
- Carga los 48 prompts del paso anterior
- Agrupa por intenciÃ³n para asegurar balance
- Divide cada intenciÃ³n: 80% entrenamiento (9 ejemplos) + 20% validaciÃ³n (3 ejemplos)
- Mezcla aleatoriamente cada conjunto (con seed=42 para reproducibilidad)
- Valida que todas las intenciones estÃ©n presentes en ambos conjuntos
- Guarda archivos separados para entrenamiento y validaciÃ³n

**Entrada**: `data/processed/training_prompts.jsonl`
**Salida**: 
- `data/training/train_data.jsonl` (36 prompts)
- `data/validation/validation_data.jsonl` (12 prompts)

### ğŸ”¸ **04_prepare_data.py** - Preparar Datos para Fine-Tuning
**PropÃ³sito**: Valida y prepara los datos finales asegurando cumplimiento con Azure OpenAI.

**QuÃ© hace**:
- Carga datos de entrenamiento y validaciÃ³n
- Valida formato requerido por Azure OpenAI:
  - Estructura de mensajes correcta (system/user/assistant)
  - Contenido no vacÃ­o en cada mensaje
  - Termina con respuesta del assistant
- Calcula estadÃ­sticas: nÃºmero de tokens estimados, ejemplos por conjunto
- Crea resumen con mÃ©tricas y estado de validaciÃ³n
- Confirma que estÃ¡ listo para fine-tuning

**Entrada**: `train_data.jsonl` + `validation_data.jsonl`
**Salida**: `data/processed/data_preparation_summary.json` (mÃ©tricas)

### ğŸ”¸ **05_fine_tuning.py** - Ejecutar Fine-Tuning en Azure
**PropÃ³sito**: Realiza el entrenamiento del modelo usando la API de Azure OpenAI.

**QuÃ© hace**:
- Conecta con Azure OpenAI usando credenciales del `.env`
- Sube archivos de entrenamiento y validaciÃ³n a Azure
- Espera a que Azure procese los archivos (estado "processed")
- Inicia job de fine-tuning con hiperparÃ¡metros configurados:
  - Modelo base: `gpt-4o-mini` (o el definido en `.env`)
  - Epochs: 3, Batch size: 1, Learning rate: 0.1
- Monitorea progreso del fine-tuning en tiempo real
- Guarda informaciÃ³n del modelo final y job ID

**Entrada**: Archivos de datos preparados
**Salida**: `results/fine_tuning_info.json` (ID del modelo entrenado)

### ğŸ”¸ **06_deploy_model.py** - Verificar Estado del Deployment
**PropÃ³sito**: Verifica el estado del deployment del modelo fine-tuned creado manualmente en Azure Portal.

**QuÃ© hace**:
- Carga informaciÃ³n del modelo fine-tuned del paso anterior
- Verifica que el job de fine-tuning estÃ© completado exitosamente
- **ğŸ†• Busca deployments existentes** en Azure OpenAI usando la API
- Reporta el estado actual del deployment:
  - âœ… **"succeeded"** â†’ Listo para usar
  - â³ **"creating"** â†’ En proceso de creaciÃ³n
  - âŒ **Otros estados** â†’ Requiere atenciÃ³n
- Crea documentaciÃ³n de uso con la configuraciÃ³n correcta
- Guarda informaciÃ³n del deployment para los siguientes pasos

**Nota**: âš ï¸ Este script **NO crea** el deployment, solo **verifica su estado**. El deployment debe crearse manualmente en Azure Portal debido a limitaciones de la API.

**Entrada**: `results/fine_tuning_info.json`
**Salida**: `results/deployment_info.json` (informaciÃ³n del deployment + guÃ­a de uso)

### ğŸ”¸ **07_test_model.py** - Probar Modelo con Casos de Prueba
**PropÃ³sito**: EvalÃºa el rendimiento del modelo con casos de prueba nuevos.

**QuÃ© hace**:
- Carga el modelo fine-tuned desplegado
- Crea 15+ casos de prueba diversos:
  - Casos tÃ­picos para cada intenciÃ³n
  - Casos ambiguos para probar robustez
  - Frases con variaciones de longitud/estilo
- Ejecuta predicciones con el modelo
- Calcula mÃ©tricas de rendimiento:
  - Accuracy general y por intenciÃ³n
  - Casos correctos vs incorrectos
  - Matriz de confusiÃ³n implÃ­cita
- Identifica patrones de error

**Entrada**: Modelo desplegado
**Salida**: `results/test_results.json` (mÃ©tricas detalladas)

### ğŸ”¸ **08_analyze_results.py** - Analizar Resultados y Mejoras
**PropÃ³sito**: Analiza el rendimiento y genera recomendaciones de mejora.

**QuÃ© hace**:
- Carga resultados de pruebas y info de fine-tuning
- Analiza patrones de accuracy:
  - Mejor/peor intenciÃ³n performante
  - Varianza entre intenciones
  - Casos de fallo mÃ¡s comunes
- Genera sugerencias especÃ­ficas:
  - Si accuracy <70%: mÃ¡s datos, revisar etiquetas
  - Si desbalanceado: mÃ¡s ejemplos para intenciones dÃ©biles
  - Ajustes de hiperparÃ¡metros recomendados
- Crea roadmap de prÃ³ximos pasos
- Califica rendimiento (A+ a F) y da recomendaciones

**Entrada**: Todos los resultados anteriores
**Salida**: `results/improvement_analysis.json` (reporte completo)

## ï¿½ Flujo de Datos Entre Scripts

```
01_create_examples.py
         â†“ (genera)
    intent_examples.json (48 ejemplos)
         â†“ (lee)
02_create_prompts.py
         â†“ (genera)
    training_prompts.jsonl (48 prompts)
         â†“ (lee)
03_split_data.py
         â†“ (divide)
    train_data.jsonl (36) + validation_data.jsonl (12)
         â†“ (valida)
04_prepare_data.py
         â†“ (confirma formato)
    data_preparation_summary.json
         â†“ (usa archivos)
05_fine_tuning.py
         â†“ (entrena modelo)
    fine_tuning_info.json (model ID)
         â†“ (verifica)
06_deploy_model.py
         â†“ (documenta uso)
    deployment_info.json
         â†“ (usa modelo)
07_test_model.py
         â†“ (evalÃºa)
    test_results.json (mÃ©tricas)
         â†“ (analiza)
08_analyze_results.py
         â†“ (genera)
    improvement_analysis.json (recomendaciones)
```

## ğŸ“ Archivos Generados por Carpeta

### `data/raw/`
- `intent_examples.json` - Ejemplos originales por intenciÃ³n

### `data/processed/`
- `training_prompts.jsonl` - Prompts formateados para fine-tuning
- `data_preparation_summary.json` - EstadÃ­sticas de preparaciÃ³n

### `data/training/`
- `train_data.jsonl` - Conjunto de entrenamiento (36 ejemplos)

### `data/validation/`
- `validation_data.jsonl` - Conjunto de validaciÃ³n (12 ejemplos)

### `results/`
- `fine_tuning_info.json` - InformaciÃ³n del job y modelo entrenado
- `deployment_info.json` - GuÃ­a de uso del modelo desplegado
- `test_results.json` - Resultados de las pruebas de rendimiento
- `improvement_analysis.json` - AnÃ¡lisis y recomendaciones de mejora

## ï¿½ğŸš€ GuÃ­a de Uso RÃ¡pido

### 1. ConfiguraciÃ³n inicial
```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
# Editar .env con tus credenciales de Azure (ver secciÃ³n "ConfiguraciÃ³n del Archivo .env")
# IMPORTANTE: Configurar FINE_TUNED_MODEL_DEPLOYMENT despuÃ©s del deployment manual
```

### 2. Ejecutar paso a paso
```bash
# Paso 1: Crear ejemplos
python scripts/01_create_examples.py

# Paso 2: Crear prompts  
python scripts/02_create_prompts.py

# ... continuar con cada paso
```

### 3. Ejecutar proceso completo
```bash
# Ejecutar todos los pasos automÃ¡ticamente
python run_all_steps.py
```

## âš™ï¸ ConfiguraciÃ³n del Archivo .env

El archivo `.env` debe contener las siguientes variables de entorno para conectar con Azure OpenAI:

```bash
# ConfiguraciÃ³n de Azure OpenAI
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_KEY=
AZURE_OPENAI_VERSION=2024-12-01-preview
AZURE_OPENAI_MODEL=gpt-4o-mini

# Deployment del modelo fine-tuned (configurar despuÃ©s del Paso 5)
FINE_TUNED_MODEL_DEPLOYMENT=gpt-4o-mini-2024-07-18-ft-d0f4b746b7f44e9f82d81f949f823655

# ParÃ¡metros opcionales de fine-tuning
FINE_TUNING_EPOCHS=3
FINE_TUNING_BATCH_SIZE=1
FINE_TUNING_LR_MULT=0.1
FINE_TUNING_PROMPT_LOSS_WEIGHT=0.01

# DivisiÃ³n de datos
TRAIN_SPLIT=0.8
VALIDATION_SPLIT=0.2
```

### ğŸ“ **Notas importantes:**
- `AZURE_OPENAI_ENDPOINT`: URL de tu instancia de Azure OpenAI
- `AZURE_OPENAI_KEY`: Clave de API de Azure OpenAI (se encuentra en Azure Portal)
- `AZURE_OPENAI_VERSION`: VersiÃ³n de API (usa `2024-12-01-preview` para fine-tuning)
- `FINE_TUNED_MODEL_DEPLOYMENT`: Nombre del deployment del modelo fine-tuned (se configura despuÃ©s del Paso 6 manual)

## ğŸ“‹ Checklist por Paso

- [ ] **Paso 1**: Ejemplos JSON creados en `data/raw/`
- [ ] **Paso 2**: Prompts JSONL generados en `data/processed/`  
- [ ] **Paso 3**: Datos divididos en `data/training/` y `data/validation/`
- [ ] **Paso 4**: Formato validado para fine-tuning
- [ ] **Paso 5**: Modelo fine-tuned en Azure OpenAI
- [ ] **Paso 6**: âš ï¸ **Deployment manual en Azure Portal** + verificaciÃ³n con script
- [ ] **Paso 7**: Modelo testeado con casos de prueba
- [ ] **Paso 8**: AnÃ¡lisis de resultados completado
- [ ] **Paso 6**: Modelo desplegado y accesible
- [ ] **Paso 7**: Pruebas ejecutadas con mÃ©tricas
- [ ] **Paso 8**: AnÃ¡lisis y recomendaciones generadas